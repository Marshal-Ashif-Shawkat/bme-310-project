{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.11","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":377107,"sourceType":"datasetVersion","datasetId":165566},{"sourceType":"datasetVersion","sourceId":11462836,"datasetId":7182917}],"dockerImageVersionId":31011,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import torch\nimport torchvision\nprint(torch.__version__)\nprint(torchvision.__version__)\n\nimport random\nimport numpy as np\nimport matplotlib.pyplot as plt\n\nfrom pathlib import Path\nfrom PIL import Image","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:23.880016Z","iopub.execute_input":"2025-04-18T14:29:23.880920Z","iopub.status.idle":"2025-04-18T14:29:30.600578Z","shell.execute_reply.started":"2025-04-18T14:29:23.880895Z","shell.execute_reply":"2025-04-18T14:29:30.599914Z"}},"outputs":[{"name":"stdout","text":"2.5.1+cu124\n0.20.1+cu124\n","output_type":"stream"}],"execution_count":1},{"cell_type":"code","source":"import os\nos.environ[\"CUBLAS_WORKSPACE_CONFIG\"] = \":4096:8\"  # Or \":16:8\"\ntorch.backends.cudnn.benchmark = False\ntorch.backends.cudnn.deterministic = True\ntorch.use_deterministic_algorithms(True, warn_only=True)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:30.601763Z","iopub.execute_input":"2025-04-18T14:29:30.602080Z","iopub.status.idle":"2025-04-18T14:29:30.606062Z","shell.execute_reply.started":"2025-04-18T14:29:30.602062Z","shell.execute_reply":"2025-04-18T14:29:30.605421Z"}},"outputs":[],"execution_count":2},{"cell_type":"code","source":"device = 'cuda' if torch.cuda.is_available() else 'cpu'\nprint(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:30.606886Z","iopub.execute_input":"2025-04-18T14:29:30.607158Z","iopub.status.idle":"2025-04-18T14:29:30.692853Z","shell.execute_reply.started":"2025-04-18T14:29:30.607136Z","shell.execute_reply":"2025-04-18T14:29:30.692079Z"}},"outputs":[{"name":"stdout","text":"cuda\n","output_type":"stream"}],"execution_count":3},{"cell_type":"code","source":"SEED = 42\n\ndef set_seed(SEED):\n    torch.manual_seed(SEED)\n    random.seed(SEED)\n    np.random.seed(SEED)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:30.694753Z","iopub.execute_input":"2025-04-18T14:29:30.695000Z","iopub.status.idle":"2025-04-18T14:29:30.709865Z","shell.execute_reply.started":"2025-04-18T14:29:30.694983Z","shell.execute_reply":"2025-04-18T14:29:30.709262Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"def seed_worker(worker_id):\n    worker_seed = torch.initial_seed() % 2**32\n    np.random.seed(worker_seed)\n    random.seed(worker_seed)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:30.710497Z","iopub.execute_input":"2025-04-18T14:29:30.710691Z","iopub.status.idle":"2025-04-18T14:29:30.727093Z","shell.execute_reply.started":"2025-04-18T14:29:30.710675Z","shell.execute_reply":"2025-04-18T14:29:30.726384Z"}},"outputs":[],"execution_count":5},{"cell_type":"markdown","source":"## Dataset","metadata":{}},{"cell_type":"code","source":"from torchvision import transforms\n\nRESIZE = 256\nCROP = 224\n\ntransform_list = transforms.Compose([\n    transforms.Resize(size=(RESIZE,RESIZE)),\n    transforms.CenterCrop(size=(CROP,CROP)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                                 std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:30.727851Z","iopub.execute_input":"2025-04-18T14:29:30.728018Z","iopub.status.idle":"2025-04-18T14:29:30.742536Z","shell.execute_reply.started":"2025-04-18T14:29:30.728004Z","shell.execute_reply":"2025-04-18T14:29:30.741833Z"}},"outputs":[],"execution_count":6},{"cell_type":"code","source":"from torch.utils.data import Dataset\n\nclass mri_dataset(Dataset):\n    def __init__(self, root_dir, transform = None):\n        self.root_dir = root_dir\n        self.imgs_path_list = list(root_dir.rglob(\"*.*\"))\n        self.transform = transform\n\n    def __len__(self):\n        return len(self.imgs_path_list)\n\n    def __getitem__(self, idx):\n        img_path = self.imgs_path_list[idx]\n        img = Image.open(img_path).convert('RGB')\n        if self.transform:\n            img = self.transform(img)\n\n        if img_path.parent.name == 'no':\n            label = 0\n        elif img_path.parent.name == 'yes':\n            label = 1\n\n        return img, label","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:30.743227Z","iopub.execute_input":"2025-04-18T14:29:30.743414Z","iopub.status.idle":"2025-04-18T14:29:30.759575Z","shell.execute_reply.started":"2025-04-18T14:29:30.743395Z","shell.execute_reply":"2025-04-18T14:29:30.758924Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"root_dir = Path(\"/kaggle/input/tiny-brain-tumor-mri/brain_tumor_dataset\")\ntotal_ds = mri_dataset(root_dir, transform_list)\nprint(f\"Total number of images: {len(total_ds)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:30.760335Z","iopub.execute_input":"2025-04-18T14:29:30.760575Z","iopub.status.idle":"2025-04-18T14:29:31.100252Z","shell.execute_reply.started":"2025-04-18T14:29:30.760552Z","shell.execute_reply":"2025-04-18T14:29:31.099649Z"}},"outputs":[{"name":"stdout","text":"Total number of images: 253\n","output_type":"stream"}],"execution_count":8},{"cell_type":"code","source":"from torch.utils.data import random_split\n\ntrain_size = 0.8\n\ngenerator = torch.Generator().manual_seed(0)\ntrain_ds, test_ds = random_split(total_ds, [train_size, 1-train_size], generator=generator)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:31.100933Z","iopub.execute_input":"2025-04-18T14:29:31.101208Z","iopub.status.idle":"2025-04-18T14:29:31.127593Z","shell.execute_reply.started":"2025-04-18T14:29:31.101189Z","shell.execute_reply":"2025-04-18T14:29:31.127103Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"from torch.utils.data import DataLoader\nimport os\n\nNUM_WORKERS = os.cpu_count()\nBATCH_SIZE = 64\n\ng = torch.Generator()\ng.manual_seed(0)\n\n# You have to turn off shuffle to have sampler\ntrain_dataloader = DataLoader(train_ds, batch_size=BATCH_SIZE, shuffle=True, num_workers=NUM_WORKERS, \n                              pin_memory=True, worker_init_fn=seed_worker, generator=g)\ntest_dataloader = DataLoader(test_ds, batch_size=BATCH_SIZE, shuffle=False, num_workers=NUM_WORKERS, \n                              pin_memory=True, worker_init_fn=seed_worker, generator=g)\n\nprint(f\"No. of batch in training: {len(train_dataloader)}\")\nprint(f\"No. of batch in training: {len(test_dataloader)}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:31.129958Z","iopub.execute_input":"2025-04-18T14:29:31.130150Z","iopub.status.idle":"2025-04-18T14:29:31.135567Z","shell.execute_reply.started":"2025-04-18T14:29:31.130135Z","shell.execute_reply":"2025-04-18T14:29:31.134833Z"}},"outputs":[{"name":"stdout","text":"No. of batch in training: 4\nNo. of batch in training: 1\n","output_type":"stream"}],"execution_count":10},{"cell_type":"markdown","source":"## Model","metadata":{}},{"cell_type":"code","source":"from torch import nn\nimport torch.nn.functional as F\n\nclass Conv_Block(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n        self.conv2d = nn.Conv2d(in_channels=in_c, out_channels=out_c, kernel_size=3)\n        self.bn = nn.BatchNorm2d(num_features=out_c)\n\n    def forward(self, x):\n        return F.relu(self.bn(self.conv2d(x)))\n\nclass Dense_Block(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n        self.dense = nn.Linear(in_features=in_c, out_features=out_c, bias=True)\n        self.bn = nn.BatchNorm1d(num_features=out_c)\n\n    def forward(self, x):\n        return F.relu(self.bn(self.dense(x)))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:31.136372Z","iopub.execute_input":"2025-04-18T14:29:31.136604Z","iopub.status.idle":"2025-04-18T14:29:31.150858Z","shell.execute_reply.started":"2025-04-18T14:29:31.136580Z","shell.execute_reply":"2025-04-18T14:29:31.150276Z"}},"outputs":[],"execution_count":11},{"cell_type":"code","source":"class ChannelAttentionModule(nn.Module):\n    def __init__(self, in_c, ratio):\n        super().__init__()\n        self.shared_mlp = nn.Sequential(\n            nn.Linear(in_c, in_c//ratio, bias=True),\n            nn.ReLU(),\n            nn.Linear(in_c//ratio, in_c, bias=True)\n        )\n\n    def forward(self, x):\n        y1 = F.max_pool2d(x, kernel_size=x.shape[2:])\n        y2 = F.avg_pool2d(x, kernel_size=x.shape[2:])\n\n        y1 = y1.view(y1.shape[0], -1)\n        y1 = self.shared_mlp(y1)\n        y2 = y2.view(y2.shape[0], -1)\n        y2 = self.shared_mlp(y2)\n\n        out = y1 + y2\n        out = F.sigmoid(out)\n        return out\n\nclass SpatialAttentionModule(nn.Module):\n    def __init__(self):\n        super().__init__()\n        self.conv2d = nn.Conv2d(in_channels=2, out_channels=1, kernel_size=7, padding=3)\n\n    def forward(self, x):\n        y_max = x.max(dim=1, keepdim=True).values\n        y_avg = x.mean(dim=1, keepdim=True)\n        y = torch.cat((y_max, y_avg), dim=1)\n        y = F.sigmoid(self.conv2d(y))\n        return y\n\nclass CBAM_Block(nn.Module):\n    def __init__(self, in_c, ratio=8):\n        super().__init__()\n        self.cam = ChannelAttentionModule(in_c, ratio=8)\n        self.sam = SpatialAttentionModule()\n\n    def forward(self, x):\n        y = self.cam(x)\n        y_cam = x * y.unsqueeze(2).unsqueeze(3)\n        y = self.sam(y_cam)\n        out = y_cam * y \n        return out","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:31.151533Z","iopub.execute_input":"2025-04-18T14:29:31.151737Z","iopub.status.idle":"2025-04-18T14:29:31.162681Z","shell.execute_reply.started":"2025-04-18T14:29:31.151722Z","shell.execute_reply":"2025-04-18T14:29:31.161982Z"}},"outputs":[],"execution_count":12},{"cell_type":"code","source":"class Residual_Block(nn.Module):\n    def __init__(self, in_c, out_c):\n        super().__init__()\n        self.conv2d1 = nn.Conv2d(in_channels=in_c, out_channels=out_c, kernel_size=3, padding=1)\n        self.conv2d2 = nn.Conv2d(in_channels=out_c, out_channels=out_c, kernel_size=3, padding=1)\n        self.bn1 = nn.BatchNorm2d(out_c)\n        self.bn2 = nn.BatchNorm2d(out_c)\n\n    def forward(self, x):\n        y = self.bn2(self.conv2d2(F.leaky_relu(self.bn1(self.conv2d1(x)))))\n        out = y + x\n        return F.leaky_relu(out)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:31.163246Z","iopub.execute_input":"2025-04-18T14:29:31.163438Z","iopub.status.idle":"2025-04-18T14:29:31.181857Z","shell.execute_reply.started":"2025-04-18T14:29:31.163423Z","shell.execute_reply":"2025-04-18T14:29:31.181194Z"}},"outputs":[],"execution_count":13},{"cell_type":"code","source":"class BrainMRNet(nn.Module):\n    def __init__(self, num_classes):\n        super().__init__()\n\n        # Stage 1\n        self.convblock11 = Conv_Block(in_c=3, out_c=32)\n        self.convblock12 = Conv_Block(in_c=32, out_c=32)\n        self.maxpool1 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # Stage 2\n        self.convblock21 = Conv_Block(in_c=32, out_c=64)\n        self.cbamblock21 = CBAM_Block(in_c=64, ratio=8)\n        self.residualblock21 = Residual_Block(in_c=64, out_c=64)\n        self.maxpool2 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n\n        # Stage 3\n        self.convblock31 = Conv_Block(in_c=64, out_c=128)\n        self.cbamblock31 = CBAM_Block(in_c=128, ratio=8)\n        self.residualblock31 = Residual_Block(in_c=128, out_c=128)\n        self.maxpool3 = torch.nn.MaxPool2d(kernel_size=2, stride=2)\n\n        self.denseblock1 = Dense_Block(in_c=16, out_c=256)\n        self.dropout = nn.Dropout(p=0.3)\n        self.denseblock2 = Dense_Block(in_c=256, out_c=256)\n        self.classifier = nn.Linear(in_features=256, out_features=num_classes)\n        \n\n    def forward(self, x):\n        y1 = self.maxpool1(self.convblock12(self.convblock11(x)))\n        y2 = self.maxpool2(self.residualblock21(self.cbamblock21(self.convblock21(y1))))\n        y3 = self.maxpool3(self.residualblock31(self.cbamblock31(self.convblock31(y2))))\n\n        y1 = F.interpolate(y1, size=(4,4), mode='bilinear')\n        y2 = F.interpolate(y2, size=(4,4), mode='bilinear')\n        y3 = F.interpolate(y3, size=(4,4), mode='bilinear')\n        \n        y = torch.cat((y1, y2, y3), dim=1)\n        y = y.mean(dim=1, keepdim=True)\n        y = y.view(y.shape[0], -1)\n        y = self.classifier(self.denseblock2(self.dropout(self.denseblock1(y))))\n        return y","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:31.182573Z","iopub.execute_input":"2025-04-18T14:29:31.182754Z","iopub.status.idle":"2025-04-18T14:29:31.197299Z","shell.execute_reply.started":"2025-04-18T14:29:31.182740Z","shell.execute_reply":"2025-04-18T14:29:31.196671Z"}},"outputs":[],"execution_count":14},{"cell_type":"code","source":"set_seed(SEED)\nmodel = BrainMRNet(num_classes=2).to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:31.197894Z","iopub.execute_input":"2025-04-18T14:29:31.198102Z","iopub.status.idle":"2025-04-18T14:29:31.431098Z","shell.execute_reply.started":"2025-04-18T14:29:31.198088Z","shell.execute_reply":"2025-04-18T14:29:31.430498Z"}},"outputs":[],"execution_count":15},{"cell_type":"code","source":"total_params = sum(p.numel() for p in model.parameters())\nprint(f\"Number of parameters: {total_params / 1e6} M\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:33:47.411530Z","iopub.execute_input":"2025-04-18T14:33:47.411800Z","iopub.status.idle":"2025-04-18T14:33:47.417002Z","shell.execute_reply.started":"2025-04-18T14:33:47.411781Z","shell.execute_reply":"2025-04-18T14:33:47.416315Z"}},"outputs":[{"name":"stdout","text":"Number of parameters: 0.550016 M\n","output_type":"stream"}],"execution_count":32},{"cell_type":"markdown","source":"## Training","metadata":{}},{"cell_type":"code","source":"def train_step(model: torch.nn.Module,\n               dataloader: torch.utils.data.DataLoader,\n               loss_fn: torch.nn.Module,\n               optimizer: torch.optim.Optimizer):\n    # Put model in train mode\n    model.train()\n\n    # Setup train loss and train accuracy values\n    train_loss, train_acc = 0, 0\n\n    # Loop through data loader data batches\n    for batch, (X, y) in enumerate(dataloader):\n        # Send data to target device\n        X, y = X.to(device), y.to(device)\n\n        # 1. Forward pass\n        y_pred = model(X)\n        y_pred = y_pred.squeeze() # [1, BATCH_SIZE] -> [BATCH_SIZE]\n        \n        # 2. Calculate  and accumulate loss\n        loss = loss_fn(y_pred, y)\n        train_loss += loss.item()\n\n        # 3. Optimizer zero grad\n        optimizer.zero_grad()\n\n        # 4. Loss backward\n        loss.backward()\n\n        # 5. Optimizer step\n        optimizer.step()\n\n        # Calculate and accumulate accuracy metric across all batches\n        y_pred_class = torch.argmax(torch.softmax(y_pred, dim=1), dim=1)\n        train_acc += (y_pred_class == y).sum().item()/len(y_pred)\n\n    # Adjust metrics to get average loss and accuracy per batch\n    train_loss = train_loss / len(dataloader)\n    train_acc = train_acc / len(dataloader)\n\n    warmup_scheduler.step() # Step the learning rate scheduler\n    current_lr = warmup_scheduler.get_last_lr()[0]\n    \n    return train_loss, train_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:31.431924Z","iopub.execute_input":"2025-04-18T14:29:31.432193Z","iopub.status.idle":"2025-04-18T14:29:31.438262Z","shell.execute_reply.started":"2025-04-18T14:29:31.432175Z","shell.execute_reply":"2025-04-18T14:29:31.437592Z"}},"outputs":[],"execution_count":16},{"cell_type":"code","source":"def test_step(model: torch.nn.Module,\n              dataloader: torch.utils.data.DataLoader,\n              loss_fn: torch.nn.Module):\n    # Put model in eval mode\n    model.eval()\n\n    # Setup test loss and test accuracy values\n    test_loss, test_acc = 0, 0\n    \n    # Turn on inference context manager\n    with torch.inference_mode():\n        # Loop through DataLoader batches\n        for batch, (X, y) in enumerate(dataloader):\n            # Send data to target device\n            X, y = X.to(device), y.to(device)\n\n            # 1. Forward pass\n            test_pred_logits = model(X)\n            test_pred_logits = test_pred_logits.squeeze() # [1, BATCH_SIZE] -> [BATCH_SIZE]\n\n            # 2. Calculate and accumulate loss\n            loss = loss_fn(test_pred_logits, y)\n            test_loss += loss.item()\n\n            # Calculate and accumulate accuracy\n\n            y_pred_class = torch.argmax(torch.softmax(test_pred_logits, dim=1), dim=1)\n            test_acc += (y_pred_class == y).sum().item()/len(test_pred_logits)\n\n    # Adjust metrics to get average loss and accuracy per batch\n    test_loss = test_loss / len(dataloader)\n    test_acc = test_acc / len(dataloader)\n    return test_loss, test_acc","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:31.439010Z","iopub.execute_input":"2025-04-18T14:29:31.439626Z","iopub.status.idle":"2025-04-18T14:29:31.458134Z","shell.execute_reply.started":"2025-04-18T14:29:31.439602Z","shell.execute_reply":"2025-04-18T14:29:31.457464Z"}},"outputs":[],"execution_count":17},{"cell_type":"code","source":"class EarlyStopping:\n    def __init__(self, patience=10, min_delta=0):\n        \"\"\"\n        Args:\n            patience (int): How many epochs to wait after the last time the test loss improved.\n            min_delta (float): Minimum change in the monitored quantity to qualify as an improvement.\n        \"\"\"\n        self.patience = patience\n        self.min_delta = min_delta\n        self.counter = 0\n        self.best_loss = float('inf')\n        self.early_stop = False\n\n    def __call__(self, test_loss):\n        if test_loss < self.best_loss - self.min_delta:\n            self.best_loss = test_loss\n            self.counter = 0  # reset counter if validation loss improves\n        else:\n            self.counter += 1\n            if self.counter >= self.patience:\n                self.early_stop = True","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:31.458797Z","iopub.execute_input":"2025-04-18T14:29:31.459017Z","iopub.status.idle":"2025-04-18T14:29:31.477651Z","shell.execute_reply.started":"2025-04-18T14:29:31.459002Z","shell.execute_reply":"2025-04-18T14:29:31.477059Z"}},"outputs":[],"execution_count":18},{"cell_type":"code","source":"MODEL_SAVE_NAME = 'best_brainmrnet_v1_brain_tumor_mri.pth'","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:31.478287Z","iopub.execute_input":"2025-04-18T14:29:31.478529Z","iopub.status.idle":"2025-04-18T14:29:31.493827Z","shell.execute_reply.started":"2025-04-18T14:29:31.478504Z","shell.execute_reply":"2025-04-18T14:29:31.493185Z"}},"outputs":[],"execution_count":19},{"cell_type":"code","source":"from tqdm.notebook import tqdm\n\n# 1. Take in various parameters required for training and test steps\ndef train(model: torch.nn.Module,\n          train_dataloader: torch.utils.data.DataLoader,\n          test_dataloader: torch.utils.data.DataLoader,\n          optimizer: torch.optim.Optimizer,\n          loss_fn: torch.nn.Module,\n          epochs):\n\n    # 2. Create empty results dictionary\n    results = {\"train_loss\": [],\n        \"train_acc\": [],\n        \"test_loss\": [],\n        \"test_acc\": []\n    }\n    \n    best_loss = float('inf')\n    early_stopping = EarlyStopping(patience=10, min_delta=0.001)\n    \n    # 3. Loop through training and testing steps for a number of epochs\n    for epoch in tqdm(range(epochs)):\n        train_loss, train_acc = train_step(model=model,\n                                           dataloader=train_dataloader,\n                                           loss_fn=loss_fn,\n                                           optimizer=optimizer)\n        test_loss, test_acc = test_step(model=model,\n            dataloader=test_dataloader,\n            loss_fn=loss_fn)\n\n        # 4. Print out what's happening\n        print(\n            f\"Epoch: {epoch} | \"\n            f\"train_loss: {train_loss:.4f} | \"\n            f\"train_acc: {train_acc:.4f} | \"\n            f\"test_loss: {test_loss:.4f} | \"\n            f\"test_acc: {test_acc:.4f} |\"\n        )\n\n        # 5. Update results dictionary\n        results[\"train_loss\"].append(train_loss)\n        results[\"train_acc\"].append(train_acc)\n        results[\"test_loss\"].append(test_loss)\n        results[\"test_acc\"].append(test_acc)\n        \n        if test_loss < best_loss:\n            torch.save(model.state_dict(), MODEL_SAVE_NAME)\n            print(\"model saved named \" + MODEL_SAVE_NAME)\n            best_loss = test_loss\n\n        early_stopping(test_loss)\n        if early_stopping.early_stop:\n            print(f\"Early stopping at epoch {epoch}\")\n            break\n\n    # 6. Return the filled results at the end of the epochs\n    return results","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:31.494655Z","iopub.execute_input":"2025-04-18T14:29:31.494905Z","iopub.status.idle":"2025-04-18T14:29:31.628445Z","shell.execute_reply.started":"2025-04-18T14:29:31.494884Z","shell.execute_reply":"2025-04-18T14:29:31.627912Z"}},"outputs":[],"execution_count":20},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim as optim\nfrom torch.optim.lr_scheduler import LambdaLR\nimport torchvision.models as models\n\nclass WarmupLRScheduler:\n    def __init__(self, optimizer, warmup_epochs, total_epochs, start_lr=1e-5, max_lr=1e-3):\n        \"\"\"\n        Create a learning rate warmup scheduler\n        \n        Args:\n            optimizer (torch.optim.Optimizer): The optimizer\n            warmup_epochs (int): Number of warmup epochs\n            total_epochs (int): Total number of training epochs\n            start_lr (float): Initial learning rate during warmup\n            max_lr (float): Maximum learning rate\n        \"\"\"\n        self.optimizer = optimizer\n        self.warmup_epochs = warmup_epochs\n        self.total_epochs = total_epochs\n        self.start_lr = start_lr\n        self.max_lr = max_lr\n        \n        # Create lambda function for learning rate scheduling\n        self.lr_lambda = self._lr_lambda()\n        self.scheduler = LambdaLR(optimizer, lr_lambda=self.lr_lambda)\n    \n    def _lr_lambda(self):\n        def lr_lambda(current_epoch):\n            if current_epoch < self.warmup_epochs:\n                # Linear warmup\n                return self.start_lr / self.max_lr + \\\n                       (current_epoch / self.warmup_epochs) * (1 - self.start_lr / self.max_lr)\n            \n            # Cosine annealing after warmup\n            progress = (current_epoch - self.warmup_epochs) / (self.total_epochs - self.warmup_epochs)\n            return max(0.0, 0.5 * (1.0 + torch.cos(torch.tensor(torch.pi * progress))))\n        \n        return lr_lambda\n    \n    def step(self):\n        \"\"\"Perform a scheduler step\"\"\"\n        self.scheduler.step()\n    \n    def get_last_lr(self):\n        \"\"\"Get the last computed learning rate\"\"\"\n        return self.scheduler.get_last_lr()","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:31.629045Z","iopub.execute_input":"2025-04-18T14:29:31.629209Z","iopub.status.idle":"2025-04-18T14:29:31.635650Z","shell.execute_reply.started":"2025-04-18T14:29:31.629196Z","shell.execute_reply":"2025-04-18T14:29:31.634936Z"}},"outputs":[],"execution_count":21},{"cell_type":"code","source":"# loss_fn = torch.nn.CrossEntropyLoss(weight=class_weights)\nloss_fn = torch.nn.CrossEntropyLoss()\n\nLR = 1e-3\nWEIGHT_DECAY = LR / 10 # 1e-4\noptimizer = torch.optim.Adam(params=model.parameters(), lr=LR, weight_decay=WEIGHT_DECAY)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:31.636235Z","iopub.execute_input":"2025-04-18T14:29:31.636453Z","iopub.status.idle":"2025-04-18T14:29:31.657010Z","shell.execute_reply.started":"2025-04-18T14:29:31.636438Z","shell.execute_reply":"2025-04-18T14:29:31.656404Z"}},"outputs":[],"execution_count":22},{"cell_type":"code","source":"# set_seed(SEED)\n\n# Set number of epochs\nNUM_EPOCHS = 100\n\n# Create warmup learning rate scheduler\nwarmup_scheduler = WarmupLRScheduler(\n    optimizer, \n    warmup_epochs=5, \n    total_epochs=NUM_EPOCHS,\n    start_lr=1e-5,  # Starting very low\n    max_lr=LR     # Maximum learning rate\n)\n\n# Start the timer\nfrom timeit import default_timer as timer\nstart_time = timer()\n\n\nmodel_0_results = train(model=model,\n                        train_dataloader=train_dataloader,\n                        test_dataloader=test_dataloader,\n                        optimizer=optimizer,\n                        loss_fn=loss_fn,\n                        epochs=NUM_EPOCHS)\n\n\n# End the timer and print out how long it took\nend_time = timer()\nprint(f\"Total training time: {(end_time-start_time)/60.0:.3f} minutes\")\ntorch.save(model.state_dict(), 'last' + MODEL_SAVE_NAME[4:])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:29:31.657807Z","iopub.execute_input":"2025-04-18T14:29:31.658299Z","iopub.status.idle":"2025-04-18T14:30:38.030087Z","shell.execute_reply.started":"2025-04-18T14:29:31.658274Z","shell.execute_reply":"2025-04-18T14:30:38.029415Z"}},"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/100 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ee36bbe9e74b4686919ee35e1813504c"}},"metadata":{}},{"name":"stdout","text":"Epoch: 0 | train_loss: 0.6585 | train_acc: 0.6577 | test_loss: 0.6875 | test_acc: 0.6000 |\nmodel saved named best_brainmrnet_v1_brain_tumor_mri.pth\nEpoch: 1 | train_loss: 0.6388 | train_acc: 0.6136 | test_loss: 0.6761 | test_acc: 0.6000 |\nmodel saved named best_brainmrnet_v1_brain_tumor_mri.pth\nEpoch: 2 | train_loss: 0.5282 | train_acc: 0.7795 | test_loss: 0.6690 | test_acc: 0.6000 |\nmodel saved named best_brainmrnet_v1_brain_tumor_mri.pth\nEpoch: 3 | train_loss: 0.4991 | train_acc: 0.7379 | test_loss: 0.6911 | test_acc: 0.6000 |\nEpoch: 4 | train_loss: 0.4703 | train_acc: 0.7379 | test_loss: 0.7413 | test_acc: 0.6000 |\nEpoch: 5 | train_loss: 0.3416 | train_acc: 0.8679 | test_loss: 0.8049 | test_acc: 0.6000 |\nEpoch: 6 | train_loss: 0.3435 | train_acc: 0.8491 | test_loss: 0.7383 | test_acc: 0.6000 |\nEpoch: 7 | train_loss: 0.3117 | train_acc: 0.8835 | test_loss: 0.5979 | test_acc: 0.6400 |\nmodel saved named best_brainmrnet_v1_brain_tumor_mri.pth\nEpoch: 8 | train_loss: 0.3082 | train_acc: 0.8530 | test_loss: 0.5505 | test_acc: 0.6800 |\nmodel saved named best_brainmrnet_v1_brain_tumor_mri.pth\nEpoch: 9 | train_loss: 0.2258 | train_acc: 0.9258 | test_loss: 0.5227 | test_acc: 0.7400 |\nmodel saved named best_brainmrnet_v1_brain_tumor_mri.pth\nEpoch: 10 | train_loss: 0.1797 | train_acc: 0.9570 | test_loss: 0.4857 | test_acc: 0.7800 |\nmodel saved named best_brainmrnet_v1_brain_tumor_mri.pth\nEpoch: 11 | train_loss: 0.2380 | train_acc: 0.9311 | test_loss: 0.4777 | test_acc: 0.7600 |\nmodel saved named best_brainmrnet_v1_brain_tumor_mri.pth\nEpoch: 12 | train_loss: 0.1244 | train_acc: 0.9688 | test_loss: 0.5099 | test_acc: 0.7200 |\nEpoch: 13 | train_loss: 0.1430 | train_acc: 0.9577 | test_loss: 0.4818 | test_acc: 0.7600 |\nEpoch: 14 | train_loss: 0.1497 | train_acc: 0.9304 | test_loss: 0.6165 | test_acc: 0.8400 |\nEpoch: 15 | train_loss: 0.1147 | train_acc: 0.9428 | test_loss: 0.7682 | test_acc: 0.7800 |\nEpoch: 16 | train_loss: 0.0936 | train_acc: 0.9766 | test_loss: 0.4855 | test_acc: 0.8400 |\nEpoch: 17 | train_loss: 0.0887 | train_acc: 0.9656 | test_loss: 0.4699 | test_acc: 0.8200 |\nmodel saved named best_brainmrnet_v1_brain_tumor_mri.pth\nEpoch: 18 | train_loss: 0.0658 | train_acc: 0.9922 | test_loss: 0.4430 | test_acc: 0.8400 |\nmodel saved named best_brainmrnet_v1_brain_tumor_mri.pth\nEpoch: 19 | train_loss: 0.0534 | train_acc: 0.9922 | test_loss: 0.3409 | test_acc: 0.8800 |\nmodel saved named best_brainmrnet_v1_brain_tumor_mri.pth\nEpoch: 20 | train_loss: 0.0619 | train_acc: 0.9734 | test_loss: 0.5063 | test_acc: 0.8200 |\nEpoch: 21 | train_loss: 0.1098 | train_acc: 0.9467 | test_loss: 0.3914 | test_acc: 0.8400 |\nEpoch: 22 | train_loss: 0.0531 | train_acc: 0.9883 | test_loss: 0.5735 | test_acc: 0.7600 |\nEpoch: 23 | train_loss: 0.2195 | train_acc: 0.9201 | test_loss: 0.5119 | test_acc: 0.8600 |\nEpoch: 24 | train_loss: 0.0730 | train_acc: 0.9766 | test_loss: 0.6438 | test_acc: 0.8400 |\nEpoch: 25 | train_loss: 0.1281 | train_acc: 0.9499 | test_loss: 0.6548 | test_acc: 0.8400 |\nEpoch: 26 | train_loss: 0.0602 | train_acc: 0.9844 | test_loss: 0.8282 | test_acc: 0.8200 |\nEpoch: 27 | train_loss: 0.1296 | train_acc: 0.9727 | test_loss: 0.7337 | test_acc: 0.7800 |\nEpoch: 28 | train_loss: 0.0523 | train_acc: 0.9883 | test_loss: 0.5671 | test_acc: 0.8800 |\nEpoch: 29 | train_loss: 0.0443 | train_acc: 0.9883 | test_loss: 0.7011 | test_acc: 0.8200 |\nEarly stopping at epoch 29\nTotal training time: 1.106 minutes\n","output_type":"stream"}],"execution_count":23},{"cell_type":"markdown","source":"## Evaluation","metadata":{}},{"cell_type":"code","source":"checkpoint_file_path = Path(\"/kaggle/working/\" + MODEL_SAVE_NAME)\nmodel.load_state_dict(torch.load(checkpoint_file_path, map_location=device, weights_only=True))","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:30:38.031217Z","iopub.execute_input":"2025-04-18T14:30:38.031544Z","iopub.status.idle":"2025-04-18T14:30:38.062169Z","shell.execute_reply.started":"2025-04-18T14:30:38.031514Z","shell.execute_reply":"2025-04-18T14:30:38.061635Z"}},"outputs":[{"execution_count":24,"output_type":"execute_result","data":{"text/plain":"<All keys matched successfully>"},"metadata":{}}],"execution_count":24},{"cell_type":"code","source":"import numpy as np\n\ndef evaluation_step(model: torch.nn.Module,\n              dataloader: torch.utils.data.DataLoader,\n              loss_fn: torch.nn.Module):\n    # Put model in eval mode\n    model.eval()\n\n    all_preds = []\n    all_labels = []\n    all_probs = []  # To store probabilities for AUC calculation\n    \n    with torch.inference_mode():\n        for batch, (X, y) in enumerate(dataloader):\n            X, y = X.to(device), y.to(device)\n\n            test_pred_logits = model(X)\n            test_pred_logits = test_pred_logits.squeeze() # [1, BATCH_SIZE] -> [BATCH_SIZE]\n\n            probs = torch.softmax(test_pred_logits, dim=1)\n            preds = torch.argmax(probs, dim=1)\n            \n            # Append predictions and labels to the list         \n            all_preds.extend(preds.cpu().numpy())\n            all_labels.extend(y.cpu().numpy())\n            all_probs.extend(probs.cpu().numpy())  # For AUC calculation\n\n    return all_preds, all_labels, all_probs","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:30:38.062839Z","iopub.execute_input":"2025-04-18T14:30:38.063038Z","iopub.status.idle":"2025-04-18T14:30:38.068638Z","shell.execute_reply.started":"2025-04-18T14:30:38.063021Z","shell.execute_reply":"2025-04-18T14:30:38.068091Z"}},"outputs":[],"execution_count":25},{"cell_type":"code","source":"from sklearn.metrics import accuracy_score, roc_auc_score, precision_score, recall_score\n\ndef print_report(y_true, y_pred, y_score, TB_label, TB_class_index):\n    accuracy = accuracy_score(y_true, y_pred)\n    auc = roc_auc_score(y_true == TB_label, y_score[:, TB_class_index])\n#     sensitivity = recall_score(y_true, y_pred, labels=[TB_label], average='macro')\n    true_positives = np.sum((all_preds == TB_label) & (all_labels == TB_label))\n    false_negatives = np.sum((all_preds != TB_label) & (all_labels == TB_label))\n    sensitivity = true_positives / (true_positives + false_negatives) # Sensitivity (Recall for TB class)\n    \n    # specificity calculation\n    true_negatives = np.sum((all_preds != TB_label) & (all_labels != TB_label)) # True Negatives: non-TB cases (Healthy or Sick but Non-TB) predicted as non-TB\n    false_positives = np.sum((all_preds == TB_label) & (all_labels != TB_label)) # False Positives: non-TB cases incorrectly predicted as TB\n    specificity = true_negatives / (true_negatives + false_positives) # Specificity (Recall for non-TB classes)\n    \n    ap = precision_score(y_true, y_pred, average='macro')\n    ar = recall_score(y_true, y_pred, average='macro')\n    \n    print(f\"accuracy: {accuracy:.4f}\")\n    print(f\"auc: {auc:.4f}\")\n    print(f\"sensitivity: {sensitivity:.4f}\")\n    print(f\"specificity: {specificity:.4f}\")\n    print(f\"average precision: {ap:.4f}\")\n    print(f\"average recall: {ar:.4f}\")","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:30:38.069447Z","iopub.execute_input":"2025-04-18T14:30:38.069646Z","iopub.status.idle":"2025-04-18T14:30:38.748390Z","shell.execute_reply.started":"2025-04-18T14:30:38.069630Z","shell.execute_reply":"2025-04-18T14:30:38.747764Z"}},"outputs":[],"execution_count":26},{"cell_type":"code","source":"TB_label = 1  # TB is represented by label 1 in the dataset\nTB_class_index = 1 # TB corresponds to index 1 in the probability outputs\n\nall_preds, all_labels, all_probs = evaluation_step(model, test_dataloader, loss_fn)\n# Convert lists to numpy arrays for metric calculations\nall_preds = np.array(all_preds)\nall_labels = np.array(all_labels)\nall_probs = np.array(all_probs)\nprint_report(y_true=all_labels, y_pred=all_preds, y_score=all_probs, TB_label=TB_label, TB_class_index=TB_class_index)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-04-18T14:30:38.749244Z","iopub.execute_input":"2025-04-18T14:30:38.749574Z","iopub.status.idle":"2025-04-18T14:30:39.271923Z","shell.execute_reply.started":"2025-04-18T14:30:38.749556Z","shell.execute_reply":"2025-04-18T14:30:39.271045Z"}},"outputs":[{"name":"stdout","text":"accuracy: 0.8800\nauc: 0.9167\nsensitivity: 0.9333\nspecificity: 0.8000\naverage precision: 0.8819\naverage recall: 0.8667\n","output_type":"stream"}],"execution_count":27}]}